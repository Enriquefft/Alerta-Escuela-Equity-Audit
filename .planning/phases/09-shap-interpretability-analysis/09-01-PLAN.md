---
phase: 09-shap-interpretability-analysis
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/fairness/shap_analysis.py
  - tests/gates/test_gate_3_2.py
  - data/exports/shap_values.json
  - data/exports/figures/shap_beeswarm_global.png
  - data/exports/figures/shap_bar_top10.png
  - data/exports/figures/shap_regional_comparison.png
  - data/exports/figures/shap_force_es_peruano.png
  - data/exports/figures/shap_force_es_mujer.png
autonomous: false

must_haves:
  truths:
    - "Global SHAP values computed on 2023 test set (25,635 rows x 25 features)"
    - "Top-5 SHAP features documented alongside top-5 LR coefficient features with overlap count"
    - "Regional SHAP computed separately for Costa, Sierra, Selva with per-region mean |SHAP| per feature"
    - "ES_PERUANO and ES_MUJER average SHAP magnitudes quantified and printed for review"
    - "10 representative student profiles exported with feature values, SHAP values, and calibrated probability"
    - "shap_values.json matches M4 schema with global_importance, regional, profiles, and feature_labels_es"
    - "Gate test 3.2 passes all assertions"
  artifacts:
    - path: "src/fairness/shap_analysis.py"
      provides: "SHAP pipeline: global + regional + interaction + profiles + figures + JSON"
      min_lines: 200
    - path: "tests/gates/test_gate_3_2.py"
      provides: "Gate test validating SHAP outputs"
      min_lines: 80
    - path: "data/exports/shap_values.json"
      provides: "M4-schema-compliant SHAP export"
      contains: "global_importance"
    - path: "data/exports/figures/shap_beeswarm_global.png"
      provides: "Global beeswarm visualization"
    - path: "data/exports/figures/shap_bar_top10.png"
      provides: "Top 10 feature importance bar chart"
    - path: "data/exports/figures/shap_regional_comparison.png"
      provides: "Regional cohort comparison bar chart"
    - path: "data/exports/figures/shap_force_es_peruano.png"
      provides: "Force plot for ES_PERUANO representative profile"
    - path: "data/exports/figures/shap_force_es_mujer.png"
      provides: "Force plot for ES_MUJER representative profile"
  key_links:
    - from: "src/fairness/shap_analysis.py"
      to: "data/processed/model_lgbm.joblib"
      via: "joblib.load raw LightGBM model (NOT calibrated wrapper)"
      pattern: "joblib\\.load.*model_lgbm\\.joblib"
    - from: "src/fairness/shap_analysis.py"
      to: "shap.TreeExplainer"
      via: "TreeExplainer with raw model, shap_values returns 2D ndarray"
      pattern: "shap\\.TreeExplainer"
    - from: "src/fairness/shap_analysis.py"
      to: "data/exports/shap_values.json"
      via: "json.dump with M4 schema structure"
      pattern: "json\\.dump.*shap_json"
    - from: "tests/gates/test_gate_3_2.py"
      to: "data/exports/shap_values.json"
      via: "json.load + assertions on structure and values"
      pattern: "json\\.load.*shap_values"
---

<objective>
Compute global, regional, and interaction SHAP values for the LightGBM dropout model on the 2023 test set. Quantify ES_PERUANO and ES_MUJER contributions specifically. Select 10 representative student profiles. Generate 5 publication-quality figures. Export M4-schema-compliant shap_values.json. Write and pass gate test 3.2.

Purpose: SHAP interpretability is the bridge between model predictions and policy-actionable insights. Global SHAP reveals which features drive dropout risk overall. Regional SHAP reveals where features like mother tongue matter more. ES_PERUANO and ES_MUJER SHAP magnitudes directly answer whether nationality and gender contribute to predictions, which are central equity questions.

Output: `src/fairness/shap_analysis.py`, `tests/gates/test_gate_3_2.py`, `data/exports/shap_values.json`, 5 PNG figures.
</objective>

<execution_context>
@/home/hybridz/.claude/get-shit-done/workflows/execute-plan.md
@/home/hybridz/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/09-shap-interpretability-analysis/09-RESEARCH.md

@src/data/features.py
@src/fairness/metrics.py
@src/models/baseline.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement SHAP analysis pipeline</name>
  <files>src/fairness/shap_analysis.py</files>
  <action>
Create `src/fairness/shap_analysis.py` following the established project pattern (sys.path.insert, matplotlib Agg backend, `run_shap_pipeline()` entry point, `if __name__ == "__main__"` block).

**Data loading:**
- Load raw LightGBM model from `data/processed/model_lgbm.joblib` via joblib (NOT the calibrated wrapper -- TreeExplainer requires direct tree access).
- Load `predictions_lgbm_calibrated.parquet`, filter to `split == "test_2023"` (25,635 rows).
- Load `enaho_with_features.parquet` and JOIN on `["CONGLOME", "VIVIENDA", "HOGAR", "CODPERSO", "year"]` to get MODEL_FEATURES + `region_natural` + `DEPARTAMENTO`/`department` + `FACTOR07`.
- Extract the 25 MODEL_FEATURES as a numpy array `X_test` for SHAP computation.
- Extract calibrated `prob_dropout` for profile display.
- Load `model_results.json` to get LR top-5 coefficients for overlap check.

**Import constants from features.py:** `from data.features import MODEL_FEATURES`

**CRITICAL SHAP API notes (shap 0.50.0 + LightGBM 4.6.0):**
- `shap.TreeExplainer(lgbm)` then `explainer.shap_values(X_test)` returns a SINGLE 2D ndarray shape `(n, 25)`, NOT a list. Do NOT index with `[1]`.
- `explainer.expected_value` is a scalar (base log-odds).
- SHAP values are in log-odds space (not probabilities).
- The new API `explanation = explainer(X_test)` returns an Explanation object for modern plot functions.
- The legacy API `sv = explainer.shap_values(X_test)` returns ndarray for force_plot and interaction_values.

**Step 1: Global SHAP**
- Create TreeExplainer with raw model.
- Compute SHAP values on full test set: `sv = explainer.shap_values(X_test)` -- shape (25635, 25).
- Global importance: `mean_abs_shap = np.abs(sv).mean(axis=0)` -- shape (25,).
- Sort features by importance. Print top-10 for review.
- Determine top-5 SHAP features and compare with LR top-5 by |coefficient|.
  LR top-5 (from research): lang_other_indigenous, lang_foreign, lang_quechua, is_secundaria_age, lang_aimara.
  Count overlap. Print overlap count and both lists. If overlap < 3, document why (LR is linear, SHAP captures nonlinear effects of continuous features like age that dominate LightGBM).

**Step 2: Beeswarm plot (global)**
- Use new API: `explanation = explainer(X_test)`.
- `shap.plots.beeswarm(explanation, max_display=25, show=False)`.
- `plt.tight_layout(); plt.savefig("data/exports/figures/shap_beeswarm_global.png", bbox_inches="tight", dpi=150); plt.close("all")`.

**Step 3: Top-10 bar plot**
- `shap.plots.bar(explanation, max_display=10, show=False)`.
- Save to `data/exports/figures/shap_bar_top10.png`.

**Step 4: Regional SHAP**
- Build region labels array from merged test data `region_natural` column (values: "costa", "sierra", "selva").
- Compute per-region mean |SHAP| for JSON export:
  For each region, mask sv rows, compute `np.abs(sv[mask]).mean(axis=0)`, store as dict.
- Regional cohort comparison plot: `shap.plots.bar(explanation.cohorts(regions).abs.mean(0), max_display=10, show=False)`.
- Save to `data/exports/figures/shap_regional_comparison.png`.
- Print regional top-3 features to highlight where mother tongue and poverty matter more.

**Step 5: Interaction values**
- Subsample 1000 rows: `rng = np.random.default_rng(42); sub_idx = rng.choice(X_test.shape[0], 1000, replace=False); X_sub = X_test[sub_idx]`.
- `interaction_values = explainer.shap_interaction_values(X_sub)` -- shape (1000, 25, 25).
- Compute mean absolute interaction strength for key pairs:
  - poverty_index_z x lang_other_indigenous
  - rural x es_mujer
- Store top-5 interaction pairs (by mean absolute strength) in JSON.
- Print interaction strengths for review.

**Step 6: ES_PERUANO and ES_MUJER quantification**
- `es_peruano_idx = MODEL_FEATURES.index("es_peruano")`.
- `es_mujer_idx = MODEL_FEATURES.index("es_mujer")`.
- Mean absolute SHAP: `np.abs(sv[:, es_peruano_idx]).mean()` and same for es_mujer.
- Mean signed SHAP (direction): `sv[:, es_peruano_idx].mean()` and same for es_mujer.
- Print these values prominently for human review.
- Also compute conditional means: mean SHAP for es_peruano among es_peruano==0 vs ==1 students.
  Same for es_mujer among female vs male students.

**Step 7: 10 representative student profiles**
Define 10 profile types with filter criteria (use merged DataFrame columns):

1. `lima_urban_castellano_male`: department=="15", rural==0, lang_castellano==1, es_mujer==0
2. `lima_urban_foreign`: department=="15", rural==0, es_peruano==0
3. `sierra_rural_quechua`: region_natural=="sierra", rural==1, lang_quechua==1
4. `sierra_rural_castellano`: region_natural=="sierra", rural==1, lang_castellano==1
5. `selva_rural_indigenous`: region_natural=="selva", rural==1, lang_other_indigenous==1
6. `selva_rural_castellano`: region_natural=="selva", rural==1, lang_castellano==1
7. `female_secundaria_urban`: es_mujer==1, is_secundaria_age==1, rural==0
8. `female_secundaria_rural`: es_mujer==1, is_secundaria_age==1, rural==1
9. `male_secundaria_urban`: es_mujer==0, is_secundaria_age==1, rural==0
10. `male_secundaria_rural`: es_mujer==0, is_secundaria_age==1, rural==1

For each profile type, implement `select_representative(mask, probas)`: find the row whose calibrated predicted probability is closest to the group's median probability (most "typical" student).

For `lima_urban_foreign`: only ~2 students match. Select the one closest to the group median. Flag small sample in output.

Each profile dict contains:
- `profile_id`: string identifier
- `description_es`: brief Spanish description (e.g., "Estudiante masculino, castellano, zona urbana de Lima")
- `feature_values`: dict of {feature_name: float_value} for all 25 MODEL_FEATURES
- `shap_values`: dict of {feature_name: float_shap_value} for all 25 features
- `predicted_probability`: calibrated probability (from `prob_dropout`)
- `base_value`: explainer.expected_value (scalar, log-odds)
- `raw_prediction`: sum(shap_values) + base_value (log-odds)
- `n_in_group`: how many students matched the filter
- `flagged_small_sample`: true if n_in_group < 30

**Step 8: Force plots for ES_PERUANO and ES_MUJER profiles**
- For the `lima_urban_foreign` profile (ES_PERUANO focus): use legacy API force_plot.
  `shap.force_plot(explainer.expected_value, sv[idx:idx+1], X_test[idx:idx+1], feature_names=list(MODEL_FEATURES), matplotlib=True, show=False)`.
  Save to `data/exports/figures/shap_force_es_peruano.png`.
- For the `female_secundaria_rural` profile (ES_MUJER focus): same pattern.
  Save to `data/exports/figures/shap_force_es_mujer.png`.

**Step 9: Build and export shap_values.json**
Define Spanish feature labels (FEATURE_LABELS_ES list from research -- 25 labels matching MODEL_FEATURES order).

JSON structure:
```python
shap_json = {
    "generated_at": datetime.now(timezone.utc).isoformat(),
    "model": "lightgbm",
    "computed_on": "test_2023",
    "n_test": 25635,
    "shap_space": "log_odds",
    "base_value": float(explainer.expected_value),
    "feature_names": list(MODEL_FEATURES),
    "feature_labels_es": FEATURE_LABELS_ES,
    "global_importance": {feat: round(float(val), 6) for feat, val in zip(MODEL_FEATURES, mean_abs_shap)},
    "top_5_shap": [feat for feat, _ in sorted_features[:5]],
    "top_5_lr": ["lang_other_indigenous", "lang_foreign", "lang_quechua", "is_secundaria_age", "lang_aimara"],
    "overlap_count": overlap_count,
    "overlap_features": overlap_list,
    "overlap_note": "..." (if overlap < 3, explain why),
    "regional": {
        "costa": {feat: round(float(v), 6) for feat, v in zip(MODEL_FEATURES, costa_shap)},
        "sierra": {feat: round(float(v), 6) for feat, v in zip(MODEL_FEATURES, sierra_shap)},
        "selva": {feat: round(float(v), 6) for feat, v in zip(MODEL_FEATURES, selva_shap)},
    },
    "es_peruano": {
        "mean_abs_shap": round(float(...), 6),
        "mean_signed_shap": round(float(...), 6),
        "rank": int (1-indexed position in global importance),
    },
    "es_mujer": {
        "mean_abs_shap": round(float(...), 6),
        "mean_signed_shap": round(float(...), 6),
        "rank": int,
    },
    "interactions": {
        "subsample_n": 1000,
        "key_pairs": [
            {"feature_a": "...", "feature_b": "...", "mean_abs_interaction": round(float(...), 6)},
            ...
        ],
    },
    "profiles": profiles_list,  # list of 10 profile dicts
}
```

Write to `data/exports/shap_values.json` with `indent=2`.

**Step 10: Console summary for human review**
Print prominently:
- Top-10 global SHAP features with values
- LR vs SHAP top-5 overlap count and features
- ES_PERUANO magnitude and rank
- ES_MUJER magnitude and rank
- Regional top-3 differences
- Key interaction strengths
- Profile count and any small-sample flags

**Ensure all figures directory exists:** `Path("data/exports/figures").mkdir(parents=True, exist_ok=True)` early in the pipeline.
  </action>
  <verify>
Run: `uv run python src/fairness/shap_analysis.py`

Expected:
- No errors or crashes
- Console prints top-10 SHAP features, overlap count, ES_PERUANO/ES_MUJER magnitudes
- `data/exports/shap_values.json` created (>10 KB)
- 5 PNG files created in `data/exports/figures/`
- 10 profiles in JSON, each with 25 feature_values and 25 shap_values

Verify manually: `ls -la data/exports/shap_values.json data/exports/figures/shap_*.png`
  </verify>
  <done>
shap_values.json exists with global_importance (25 features), regional (3 regions), profiles (10 entries), es_peruano, es_mujer, and interactions sections. 5 SHAP figures exported as PNG. Console output shows SHAP top-5, overlap with LR, ES_PERUANO/ES_MUJER magnitudes, and regional differences.
  </done>
</task>

<task type="auto">
  <name>Task 2: Write gate test 3.2</name>
  <files>tests/gates/test_gate_3_2.py</files>
  <action>
Create `tests/gates/test_gate_3_2.py` following the pattern from `test_gate_3_1.py` (sys.path.insert, ROOT = find_project_root(), fixture loading JSON, assertion tests + human-review print test).

**Fixture:**
```python
SHAP_PATH = ROOT / "data" / "exports" / "shap_values.json"

@pytest.fixture(scope="module")
def shap_data():
    assert SHAP_PATH.exists(), "shap_values.json not found. Run: uv run python src/fairness/shap_analysis.py"
    with open(SHAP_PATH) as f:
        return json.load(f)
```

**Test functions:**

1. `test_json_exists_and_valid(shap_data)`: Assert top-level keys exist: generated_at, model, computed_on, n_test, feature_names, feature_labels_es, global_importance, regional, profiles, es_peruano, es_mujer, interactions.

2. `test_global_importance_complete(shap_data)`: Assert global_importance has exactly 25 features. Assert all values are non-negative floats. Assert sum > 0 (not all zeros).

3. `test_feature_names_match(shap_data)`: Import MODEL_FEATURES from `data.features`. Assert `shap_data["feature_names"] == list(MODEL_FEATURES)`.

4. `test_feature_labels_es_complete(shap_data)`: Assert feature_labels_es has exactly 25 entries. Assert all are non-empty strings.

5. `test_regional_shap_complete(shap_data)`: Assert "regional" has keys "costa", "sierra", "selva". Each region has 25 feature entries. Values are non-negative.

6. `test_lr_overlap_documented(shap_data)`: Assert top_5_shap has 5 entries. Assert top_5_lr has 5 entries. Assert overlap_count is an integer >= 0. Print overlap count and features. NOTE: The gate criterion is 3/5 overlap. If overlap < 3, assert overlap_note is a non-empty string explaining why. Do NOT fail the test if overlap < 3 -- document it.

7. `test_es_peruano_es_mujer_quantified(shap_data)`: Assert es_peruano and es_mujer sections have mean_abs_shap, mean_signed_shap, rank. Assert mean_abs_shap >= 0. Assert rank is between 1 and 25.

8. `test_profiles_complete(shap_data)`: Assert profiles has exactly 10 entries. Each profile has: profile_id, feature_values (25 keys), shap_values (25 keys), predicted_probability (0-1 range), base_value, n_in_group (>0).

9. `test_interactions_present(shap_data)`: Assert interactions section has subsample_n (1000) and key_pairs (list with at least 2 entries). Each pair has feature_a, feature_b, mean_abs_interaction.

10. `test_figures_exist()`: Assert all 5 PNG files exist in data/exports/figures/: shap_beeswarm_global.png, shap_bar_top10.png, shap_regional_comparison.png, shap_force_es_peruano.png, shap_force_es_mujer.png. Each file size > 0.

11. `test_print_human_review(shap_data)`: Print formatted tables for human review (always passes):
    - Top-10 global SHAP features with importance values
    - LR vs SHAP top-5 overlap: features and count
    - ES_PERUANO: mean |SHAP|, rank, signed SHAP
    - ES_MUJER: mean |SHAP|, rank, signed SHAP
    - Regional top-3 features for each region
    - Interaction pairs with strengths
    - Profile summary (id, n_in_group, predicted_probability, any flags)
  </action>
  <verify>
Run: `uv run pytest tests/gates/test_gate_3_2.py -v -s`

Expected: All 11 tests pass. Human-review output prints SHAP top-5, ES_PERUANO/ES_MUJER magnitudes, regional differences, and profile summaries.
  </verify>
  <done>
Gate test 3.2 passes all 11 tests. Console output shows top-5 SHAP features, LR overlap count, ES_PERUANO and ES_MUJER magnitudes with ranks, regional differences, and 10 profile summaries for human review.
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>
SHAP interpretability analysis for the LightGBM dropout model:
- Global SHAP values on 25,635 test set rows (25 features)
- Regional SHAP for Costa, Sierra, Selva
- ES_PERUANO and ES_MUJER SHAP magnitudes quantified
- 10 representative student profiles with SHAP breakdowns
- 5 publication-quality figures (beeswarm, bar, regional comparison, 2 force plots)
- M4-schema-compliant shap_values.json export
- Gate test 3.2 passing all assertions
  </what-built>
  <how-to-verify>
Run `uv run pytest tests/gates/test_gate_3_2.py -v -s` and review the printed output:

1. **Top-5 SHAP features**: Do they make intuitive sense for dropout prediction? (age, poverty, language features expected to be prominent)

2. **LR vs SHAP overlap**: How many of the top-5 overlap? If < 3, is the explanation reasonable? (LR is linear, SHAP captures nonlinear effects -- continuous features like age may dominate in SHAP but not LR)

3. **ES_PERUANO magnitude**: How large is the nationality SHAP effect? Given only 27 non-Peruvian students in test set, expect small average effect. Is this consistent with Phase 8 findings (small sample, minimal mention)?

4. **ES_MUJER magnitude and sign**: Does gender SHAP match expectations? Check if negative (protective for females in primaria) or context-dependent.

5. **Regional differences**: Does mother tongue (lang_other_indigenous, lang_quechua) SHAP increase in Selva/Sierra vs Costa? Does poverty matter more in rural regions?

6. **Profile intuition**: Review the 10 profiles. Do SHAP values make directional sense? (e.g., rural indigenous student should have higher dropout-pushing SHAP values for lang_other_indigenous)

7. **Figures**: Open the 5 PNGs in data/exports/figures/ and verify they are readable and informative.
  </how-to-verify>
  <resume-signal>Type "approved" or describe issues with specific features/figures/magnitudes to adjust</resume-signal>
</task>

</tasks>

<verification>
After all tasks complete:
1. `uv run python src/fairness/shap_analysis.py` runs without errors
2. `uv run pytest tests/gates/test_gate_3_2.py -v -s` passes all 11 tests
3. `data/exports/shap_values.json` is valid JSON with all required sections
4. 5 PNG figures exist and are non-empty
5. Human reviews SHAP feature rankings, ES_PERUANO/ES_MUJER magnitudes, regional patterns, and profile intuition
</verification>

<success_criteria>
- Global SHAP values computed for all 25 features on 2023 test set
- Top-5 SHAP vs LR overlap documented (count and explanation if < 3)
- Regional SHAP for Costa, Sierra, Selva with meaningful differences
- ES_PERUANO and ES_MUJER magnitudes quantified with rank and signed direction
- 10 representative profiles with feature values, SHAP values, and calibrated probability
- shap_values.json valid and M4-schema-compliant
- Gate test 3.2: 11/11 passing
- Human approves feature intuition, nationality magnitude, gender effects, and regional patterns
</success_criteria>

<output>
After completion, create `.planning/phases/09-shap-interpretability-analysis/09-01-SUMMARY.md`
</output>
