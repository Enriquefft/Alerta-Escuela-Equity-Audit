---
phase: 04-feature-engineering-descriptive-statistics
plan: 02
type: execute
wave: 2
depends_on: ["04-01"]
files_modified:
  - src/data/descriptive.py
  - data/exports/descriptive_tables.json
  - data/exports/figures/01_language_bars.png
  - data/exports/figures/02_sex_education_bars.png
  - data/exports/figures/03_rural_urban_bars.png
  - data/exports/figures/04_region_bars.png
  - data/exports/figures/05_poverty_quintile_bars.png
  - data/exports/figures/06_language_rurality_heatmap.png
  - data/exports/figures/07_temporal_trend_lines.png
  - tests/gates/test_gate_1_5.py
autonomous: false

must_haves:
  truths:
    - "Survey-weighted Awajun dropout rate exceeds 18% for 2020+ years"
    - "Castellano weighted dropout rate is between 10-18%"
    - "Rural dropout rate exceeds urban rate"
    - "descriptive_tables.json has all 7 breakdown keys with CIs and sample sizes"
    - "7 matplotlib PNG visualizations saved to data/exports/figures/"
    - "Gate test 1.5 passes all assertions"
  artifacts:
    - path: "src/data/descriptive.py"
      provides: "Descriptive statistics computation and visualization"
      exports: ["compute_descriptive_stats", "generate_visualizations", "export_descriptive_json"]
    - path: "data/exports/descriptive_tables.json"
      provides: "M4 schema JSON export"
    - path: "data/exports/figures/"
      provides: "7 PNG visualizations"
    - path: "tests/gates/test_gate_1_5.py"
      provides: "Gate test for features + descriptive stats + export"
  key_links:
    - from: "src/data/descriptive.py"
      to: "data/processed/enaho_with_features.parquet"
      via: "polars read_parquet"
      pattern: "pl\\.read_parquet.*enaho_with_features"
    - from: "tests/gates/test_gate_1_5.py"
      to: "data/exports/descriptive_tables.json"
      via: "json.loads validation"
      pattern: "json\\.load"
    - from: "src/data/descriptive.py"
      to: "statsmodels"
      via: "DescrStatsW for confidence intervals"
      pattern: "DescrStatsW"
---

<objective>
Compute survey-weighted descriptive statistics across all 6 fairness dimensions, generate 7 visualizations, export descriptive_tables.json matching the M4 schema, and write gate test 1.5.

Purpose: The descriptive statistics quantify dropout gaps before any modeling -- they are the foundation of the equity audit narrative. The JSON export feeds the M4 scrollytelling site. The visualizations provide human-reviewable evidence of the language equity gap (Awajun > 18%).

Output: `src/data/descriptive.py`, `data/exports/descriptive_tables.json`, 7 PNGs in `data/exports/figures/`, gate test 1.5.
</objective>

<execution_context>
@/home/hybridz/.claude/get-shit-done/workflows/execute-plan.md
@/home/hybridz/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-feature-engineering-descriptive-statistics/04-CONTEXT.md
@.planning/phases/04-feature-engineering-descriptive-statistics/04-RESEARCH.md
@.planning/phases/04-feature-engineering-descriptive-statistics/04-01-SUMMARY.md

Key source files:
@src/data/features.py -- MODEL_FEATURES, META_COLUMNS, build_features()
@data/processed/enaho_with_features.parquet -- feature matrix input
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create src/data/descriptive.py with all breakdowns, visualizations, and JSON export</name>
  <files>
    src/data/descriptive.py
    data/exports/descriptive_tables.json
    data/exports/figures/01_language_bars.png
    data/exports/figures/02_sex_education_bars.png
    data/exports/figures/03_rural_urban_bars.png
    data/exports/figures/04_region_bars.png
    data/exports/figures/05_poverty_quintile_bars.png
    data/exports/figures/06_language_rurality_heatmap.png
    data/exports/figures/07_temporal_trend_lines.png
  </files>
  <action>
Create `src/data/descriptive.py` implementing all descriptive statistics computation, visualization generation, and JSON export.

**Module structure:**

```python
import json
import logging
from datetime import datetime, timezone
from pathlib import Path
from dataclasses import dataclass, field

import numpy as np
import polars as pl
import matplotlib
matplotlib.use("Agg")  # Non-interactive backend
import matplotlib.pyplot as plt
from statsmodels.stats.weightstats import DescrStatsW

from utils import find_project_root

logger = logging.getLogger(__name__)
```

**Color palette (per research recommendation):**

```python
PALETTE = {
    "castellano": "#1f77b4",      # Blue (reference group)
    "quechua": "#2ca02c",         # Green
    "aimara": "#9467bd",          # Purple
    "awajun": "#d62728",          # Red (highlight equity gap)
    "ashaninka": "#ff7f0e",       # Orange
    "other_indigenous": "#8c564b", # Brown
    "foreign": "#7f7f7f",         # Gray
}
```

**Language group mapping function:**

Create `_assign_language_group(df: pl.DataFrame) -> pl.DataFrame` that adds a `language_group` string column based on p300a_original:
- p300a_original == 4 -> "castellano"
- p300a_original == 1 -> "quechua"
- p300a_original == 2 -> "aimara"
- p300a_original == 11 -> "awajun"
- p300a_original == 10 -> "ashaninka"
- p300a_original in (6, 7) -> "foreign"
- p300a_harmonized == 3 AND p300a_original not in (10, 11) -> "other_indigenous"
- everything else -> "other_indigenous" (fallback)

**Weighted rate + CI computation helper:**

Create `_weighted_rate_with_ci(dropout_array: np.ndarray, weight_array: np.ndarray) -> dict` that returns:
```python
{
    "weighted_rate": round(mean, 4),
    "lower_ci": round(max(0, mean - 1.96 * se), 4),
    "upper_ci": round(min(1, mean + 1.96 * se), 4),
    "n_unweighted": int(len(dropout_array)),
    "n_weighted": round(float(weight_array.sum()), 0),
}
```
Use `DescrStatsW(dropout_array, weights=weight_array)` for mean and std_mean (standard error). For groups with n < 2, return rate=0, ci=[0,0] with a warning.

**Console printing helper:**

Create `_print_table(title: str, rows: list[dict])` that prints formatted table to stdout:
```
--- DROPOUT BY MOTHER TONGUE ---
  Castellano:       0.1526  [0.1525, 0.1527]  (n=132,825)
  Quechua:          0.2038  [0.2030, 0.2046]  (n=11,230)
  Awajun:           0.2047  [0.2018, 0.2076]  (n=738)  ***
```
Add `***` annotation for Awajun to highlight equity gap.

**Main functions:**

**1. `compute_descriptive_stats(df: pl.DataFrame) -> dict`**

Takes the enaho_with_features DataFrame and returns a dict matching the JSON export schema.

Compute each breakdown:

**DESC-01: Language breakdown**
- Assign language_group column
- Group by language_group, compute weighted rate + CI for each
- Also compute binary: indigenous vs castellano as headline stat
- Print console table

**DESC-02: Sex x Education Level**
- Groups: male_primaria (P207=1, age 6-11), female_primaria (P207=2, age 6-11), male_secundaria (P207=1, age 12-17), female_secundaria (P207=2, age 12-17)
- Also simple sex breakdown: male, female
- Print console table

**DESC-03: Rural/Urban, Region, Poverty Quintile**
- Rural: rural == 1 vs rural == 0
- Region: region_natural in (costa, sierra, selva)
- Poverty: poverty_quintile in (1, 2, 3, 4, 5) labeled Q1_least_poor through Q5_most_poor
- Print console tables for each

**DESC-04: Heatmap Data (3 heatmaps per CONTEXT.md)**
1. Language x Rurality: 7 language groups x 2 (urban/rural) = 14 cells
2. Language x Poverty Quintile: 7 language groups x 5 quintiles = 35 cells
3. Language x Region: 7 language groups x 3 regions = 21 cells

For each: compute weighted rate + CI per cell. Flag cells with n < 50 in warnings.

Return as nested dict with "rows", "columns", "values" (2D array), "ci_lower", "ci_upper", "n_unweighted".

**DESC-05: Choropleth prep**
- Group by UBIGEO, compute per-district weighted dropout rate + n_students + department
- Store as list of dicts (will be used in Phase 10 for choropleth.json)
- Include in JSON under "choropleth_prep" key

**DESC-06: Temporal trends**
- Group by year, compute overall weighted rate per year
- Group by year x language_group for by-language trends
- Return: years list, overall_rate list, by_language dict of lists

Print Awajun by-year breakdown (2020-2023) specifically for success criterion visibility.

Build the full export dict with _metadata:
```python
{
    "_metadata": {
        "generated_at": datetime.now(timezone.utc).isoformat(),
        "source_rows": df.height,
        "years_covered": sorted(df["year"].unique().to_list()),
        "pipeline_version": "0.4.0",
    },
    "language": [...],
    "language_binary": [...],
    "sex": [...],
    "sex_x_level": [...],
    "rural": [...],
    "region": [...],
    "poverty": [...],
    "heatmap_language_x_rural": {...},
    "heatmap_language_x_poverty": {...},
    "heatmap_language_x_region": {...},
    "choropleth_prep": [...],
    "temporal": {...},
}
```

**2. `generate_visualizations(stats: dict, output_dir: Path) -> list[Path]`**

Takes the stats dict from compute_descriptive_stats and generates 7 matplotlib PNGs.

Create `data/exports/figures/` directory if it doesn't exist.

For all visualizations:
- Use matplotlib with Agg backend (non-interactive)
- Figure size: 10x6 for bars, 10x8 for heatmaps
- Font: 12pt axes, 14pt titles
- Include 95% CI error bars on all bar charts
- Save at 150 DPI
- plt.tight_layout() before saving
- plt.close() after saving to free memory

**Visualization 1: Language Bars (01_language_bars.png)**
- Horizontal bar chart
- Y-axis: 7 language groups (ordered by rate, highest at top)
- X-axis: Weighted dropout rate
- Colors: PALETTE per language group
- Error bars: CI whiskers
- Title: "Survey-Weighted Dropout Rate by Mother Tongue (ENAHO 2018-2023)"
- Add vertical dashed line at overall rate for reference

**Visualization 2: Sex x Education Level (02_sex_education_bars.png)**
- Grouped bar chart
- X-axis: Primaria / Secundaria
- Bars: Male and Female side by side
- Colors: blue for male, coral for female
- CI error bars
- Title: "Dropout Rate by Sex and Education Level"
- Annotate the gender flip if male_secundaria > female_secundaria

**Visualization 3: Rural/Urban (03_rural_urban_bars.png)**
- Simple 2-bar chart
- Urban vs Rural
- CI error bars
- Title: "Dropout Rate: Urban vs Rural"

**Visualization 4: Region (04_region_bars.png)**
- 3-bar chart: Costa, Sierra, Selva
- Colors: green gradients or distinct colors
- CI error bars
- Title: "Dropout Rate by Natural Region"

**Visualization 5: Poverty Quintile (05_poverty_quintile_bars.png)**
- 5-bar chart: Q1 (least poor) to Q5 (most poor)
- Gradient color from light to dark to show poverty effect
- CI error bars
- Title: "Dropout Rate by Poverty Quintile"

**Visualization 6: Language x Rurality Heatmap (06_language_rurality_heatmap.png)**
- Annotated heatmap (use matplotlib imshow or seaborn heatmap)
- Rows: 7 language groups
- Columns: Urban, Rural
- Cell values: weighted rate (formatted to 4 decimal places)
- Color scale: sequential YlOrRd (yellow-orange-red)
- Flag cells with n < 50 with asterisk
- Title: "Dropout Rate: Language x Rurality Interaction"

**Visualization 7: Temporal Trends (07_temporal_trend_lines.png)**
- Line chart
- X-axis: Year (2018-2023)
- Y-axis: Weighted dropout rate
- One line per language group, colored per PALETTE
- Highlight 2020 (COVID) with vertical dotted line
- Legend
- Title: "Dropout Rate Trends by Mother Tongue (2018-2023)"

**3. `export_descriptive_json(stats: dict, output_path: Path) -> Path`**

Serialize stats dict to JSON with:
- indent=2 for readability
- ensure_ascii=False (preserve Spanish characters)
- Round all floats to 4 decimal places (use a custom JSON encoder or pre-round all values)

Return the output path.

**4. `main()` function for standalone execution:**

```python
def main():
    """Run descriptive statistics pipeline."""
    import sys
    sys.path.insert(0, "src")

    root = find_project_root()
    df = pl.read_parquet(root / "data" / "processed" / "enaho_with_features.parquet")

    print(f"Loaded {df.height} rows, {df.width} columns")

    stats = compute_descriptive_stats(df)
    figures_dir = root / "data" / "exports" / "figures"
    paths = generate_visualizations(stats, figures_dir)
    json_path = export_descriptive_json(stats, root / "data" / "exports" / "descriptive_tables.json")

    print(f"\nJSON exported to: {json_path}")
    print(f"Figures saved to: {figures_dir}")
    for p in paths:
        print(f"  {p.name}")

if __name__ == "__main__":
    main()
```

Run the full pipeline after creating the module to generate all outputs.
  </action>
  <verify>
Run the descriptive pipeline:
```bash
uv run python src/data/descriptive.py
```

Then verify outputs:
```bash
ls -la data/exports/descriptive_tables.json
ls -la data/exports/figures/*.png
uv run python -c "
import json
with open('data/exports/descriptive_tables.json') as f:
    d = json.load(f)
print('Top-level keys:', list(d.keys()))
print('Language groups:', [r['group'] for r in d['language']])
print('Awajun rate:', [r for r in d['language'] if r['group'] == 'awajun'])
print('Temporal years:', d['temporal']['years'])
print('Metadata:', d['_metadata'])
print('Figure count:', len(list(Path('data/exports/figures').glob('*.png'))))
"
```

Verify:
- descriptive_tables.json exists, is valid JSON, has all required keys
- 7 PNG files exist in data/exports/figures/
- Awajun rate is visible in console output and > 0.18
- Console tables printed for all breakdowns
  </verify>
  <done>
- `src/data/descriptive.py` exists with compute_descriptive_stats, generate_visualizations, export_descriptive_json
- `data/exports/descriptive_tables.json` valid JSON with all 7 breakdown keys + _metadata + CIs
- 7 PNG visualizations saved to data/exports/figures/
- Console tables printed showing Awajun > 18%, Castellano 10-18%
  </done>
</task>

<task type="auto">
  <name>Task 2: Create gate test 1.5</name>
  <files>tests/gates/test_gate_1_5.py</files>
  <action>
Create `tests/gates/test_gate_1_5.py` following the established gate test pattern from test_gate_1_1.py through test_gate_1_4.py.

**Gate test structure:**

```python
"""Gate Test 1.5: Feature Engineering + Descriptive Statistics Validation.

Validates:
- Feature matrix completeness and correctness
- Binary feature encoding
- Poverty quintile balance
- Survey-weighted dropout rate thresholds
- Correlation check for multicollinearity
- descriptive_tables.json export validation
- enaho_with_features.parquet validation
"""

import json
import sys
from pathlib import Path

import numpy as np
import polars as pl
import pytest

sys.path.insert(0, str(Path(__file__).resolve().parents[2] / "src"))

from data.features import MODEL_FEATURES, META_COLUMNS
from utils import find_project_root
```

**Test functions:**

**test_feature_count()**
- Load enaho_with_features.parquet
- Assert >= 19 columns are in MODEL_FEATURES
- Assert all MODEL_FEATURES columns exist in the DataFrame
- Print: "Feature count: {n} model features"

**test_binary_features_valid()**
- Binary features: es_mujer, lang_castellano, lang_quechua, lang_aimara, lang_other_indigenous, lang_foreign, rural, is_sierra, is_selva, es_peruano, has_disability, is_working, juntos_participant, is_secundaria_age
- For each: assert unique non-null values are subset of {0, 1}
- Print each feature's value counts

**test_age_range()**
- Assert age column has min >= 6 and max <= 17
- Assert no nulls

**test_poverty_quintile_balance()**
- Assert poverty_quintile has exactly 5 unique values: {1, 2, 3, 4, 5}
- For each quintile: compute weighted share = sum(FACTOR07 where quintile==q) / sum(FACTOR07)
- Assert each share is between 0.14 and 0.26 (20% +/- 30%)
- Print quintile balance table

**test_no_high_null_features()**
- For each feature in MODEL_FEATURES: compute null percentage
- Assert no feature has > 30% nulls
- Print null rate table for features with > 0% nulls

**test_no_high_correlation()**
- Select numeric model features (exclude categoricals like region_natural)
- Compute Pearson correlation matrix (use polars or convert to numpy)
- Assert no pair has |correlation| > 0.95
- Print top-5 most correlated pairs

**test_awajun_dropout_rate()**
- Filter: p300a_original == 11 AND year >= 2020
- Compute survey-weighted dropout rate
- Assert rate > 0.18
- Print: "Awajun 2020+ weighted dropout rate: {rate:.4f} (threshold: > 0.18)"
- Also print Awajun by-year breakdown (2020, 2021, 2022, 2023)

**test_castellano_dropout_rate()**
- Filter: P300A == 4 (or use lang_castellano == 1)
- Compute survey-weighted dropout rate
- Assert 0.10 < rate < 0.18
- Print: "Castellano weighted dropout rate: {rate:.4f} (threshold: 0.10-0.18)"

**test_directional_checks()**
- Rural rate > Urban rate
- Sierra rate > Costa rate
- Assert both with descriptive print

**test_descriptive_json_exists()**
- Assert data/exports/descriptive_tables.json exists
- Load JSON, assert valid
- Assert top-level keys include: _metadata, language, sex, sex_x_level, rural, region, poverty, heatmap_language_x_rural, temporal
- Assert _metadata has: generated_at, source_rows, years_covered

**test_descriptive_json_schema()**
- For each breakdown in [language, sex, rural, region, poverty]:
  - Assert it's a list
  - Each entry has: group, weighted_rate, lower_ci, upper_ci, n_unweighted
  - Assert lower_ci <= weighted_rate <= upper_ci
  - Assert n_unweighted > 0
- Assert heatmap_language_x_rural has: rows, columns, values, ci_lower, ci_upper, n_unweighted
- Assert temporal has: years, overall_rate, by_language

**test_parquet_row_count()**
- Assert enaho_with_features.parquet has exactly 150,135 rows
- Assert contains all MODEL_FEATURES columns
- Assert contains META_COLUMNS (UBIGEO, FACTOR07, year, dropout)

**test_figures_exist()**
- Assert data/exports/figures/ directory exists
- Assert 7 PNG files exist with expected names
- Print paths to all figures

**Summary section at end of file:**

Add a standalone `if __name__ == "__main__"` block that runs all tests and prints a summary:
```
=== GATE TEST 1.5 SUMMARY ===
Feature matrix: {n} model features, 150,135 rows
Binary validation: PASS (14 features)
Quintile balance: PASS (5 groups, 14-26% each)
Awajun 2020+: {rate:.4f} > 0.18 PASS
Castellano: {rate:.4f} in [0.10, 0.18] PASS
Directional: rural > urban PASS, sierra > costa PASS
JSON export: PASS (valid, all keys present)
Figures: PASS (7 PNGs)
Parquet: PASS (150,135 rows, all features)
```
  </action>
  <verify>
Run gate test:
```bash
uv run pytest tests/gates/test_gate_1_5.py -v
```

Verify: all assertions pass, console output shows Awajun > 18%, Castellano in 10-18%, quintile balance within bounds.
  </verify>
  <done>
- Gate test 1.5 passes all assertions
- Console output shows all key metrics for human review
- Awajun dropout rate confirmed > 18% for 2020+
- Castellano rate confirmed between 10-18%
- All directional checks pass
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>
Complete descriptive statistics pipeline with:
- Survey-weighted dropout rates across 6 fairness dimensions (language, sex, rural/urban, region, poverty, temporal)
- 3 heatmap interaction analyses (language x rurality, language x poverty, language x region)
- 7 matplotlib visualizations saved as PNGs
- descriptive_tables.json matching M4 schema with confidence intervals
- Gate test 1.5 passing all assertions

Key findings to review:
- Awajun dropout rate > 18% for 2020+ (confirming the language equity gap)
- Castellano rate between 10-18% (baseline comparison)
- Rural > Urban dropout gap
- COVID spike visible in 2020 temporal trend
  </what-built>
  <how-to-verify>
1. Review console output from gate test 1.5:
   ```bash
   uv run pytest tests/gates/test_gate_1_5.py -v -s
   ```
   Check: Awajun rate, Castellano rate, quintile balance, directional checks.

2. Review 7 visualizations:
   Open the PNG files in `data/exports/figures/`:
   - 01_language_bars.png -- Awajun should be visually prominent (red bar)
   - 02_sex_education_bars.png -- check for gender flip in secundaria
   - 03_rural_urban_bars.png -- rural bar should be taller
   - 04_region_bars.png -- Sierra should be highest
   - 05_poverty_quintile_bars.png -- Q5 (most poor) should be highest
   - 06_language_rurality_heatmap.png -- darkest cell should be indigenous + rural
   - 07_temporal_trend_lines.png -- COVID spike in 2020, Awajun red line visible

3. Review descriptive_tables.json:
   ```bash
   uv run python -c "
   import json
   with open('data/exports/descriptive_tables.json') as f:
       d = json.load(f)
   for lang in d['language']:
       flag = '***' if lang['group'] == 'awajun' else ''
       print(f\"{lang['group']:25s} {lang['weighted_rate']:.4f}  [{lang['lower_ci']:.4f}, {lang['upper_ci']:.4f}]  (n={lang['n_unweighted']:,}) {flag}\")
   "
   ```

4. Confirm Awajun gap: is the difference between Awajun (>18%) and Castellano (~15%) clearly visible in both data and visualizations?
  </how-to-verify>
  <resume-signal>Type "approved" if dropout rates, visualizations, and Awajun gap look correct. Describe any issues if adjustments needed.</resume-signal>
</task>

</tasks>

<verification>
After all tasks complete:

1. `src/data/descriptive.py` exists with compute_descriptive_stats, generate_visualizations, export_descriptive_json
2. `data/exports/descriptive_tables.json` is valid JSON with: _metadata, language, sex, sex_x_level, rural, region, poverty, 3 heatmaps, temporal, choropleth_prep
3. Each breakdown entry has: weighted_rate, lower_ci, upper_ci, n_unweighted (all rounded to 4 decimal places)
4. 7 PNG files exist in data/exports/figures/
5. Gate test 1.5 passes: `uv run pytest tests/gates/test_gate_1_5.py -v`
6. Awajun 2020+ rate > 0.18, Castellano rate in [0.10, 0.18]
7. Rural > Urban, Sierra > Costa (directional checks)
8. Human approves visualizations and rates
</verification>

<success_criteria>
- Survey-weighted Awajun dropout rate exceeds 18% for 2020+ years; Castellano rate between 10-18%
- descriptive_tables.json exists, valid JSON, matches M4 schema with all breakdowns + CIs
- 7 PNG visualizations saved to data/exports/figures/
- Gate test 1.5 passes all assertions
- Human reviews and approves weighted dropout rates, visualizations, and Awajun gap
</success_criteria>

<output>
After completion, create `.planning/phases/04-feature-engineering-descriptive-statistics/04-02-SUMMARY.md`
</output>
