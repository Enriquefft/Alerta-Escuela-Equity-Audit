---
phase: 01-enaho-single-year-loader
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/utils.py
  - src/data/enaho.py
  - tests/unit/test_ubigeo.py
  - tests/unit/test_enaho_loader.py
  - tests/gates/test_gate_1_1.py
  - tests/unit/__init__.py
  - tests/gates/__init__.py
  - tests/__init__.py
autonomous: false

must_haves:
  truths:
    - "load_enaho_year(2023) returns an ENAHOResult with a polars DataFrame containing ~20K-30K school-age rows (ages 6-17)"
    - "Dropout target column exists as boolean: True where (P303==1 & P306==2), with ~2.5K-5K unweighted dropouts"
    - "FACTOR07-weighted dropout rate is between 0.10-0.18"
    - "All UBIGEO values are exactly 6 characters with no leading-zero loss"
    - "Critical columns (UBIGEO, P208A, P303, P306, FACTOR07) have zero nulls"
    - "Gate test 1.1 passes all assertions"
    - "10 random dropout rows printed for human inspection show real student records"
  artifacts:
    - path: "src/utils.py"
      provides: "find_project_root(), pad_ubigeo(), sniff_delimiter()"
      exports: ["find_project_root", "pad_ubigeo", "sniff_delimiter"]
    - path: "src/data/enaho.py"
      provides: "ENAHOResult dataclass, load_module_200(), load_module_300(), load_enaho_year()"
      exports: ["ENAHOResult", "load_module_200", "load_module_300", "load_enaho_year"]
    - path: "tests/gates/test_gate_1_1.py"
      provides: "Gate test validating row counts, dropout counts, weighted rate, UBIGEO integrity, null checks, schema validation"
    - path: "tests/unit/test_ubigeo.py"
      provides: "Unit tests for pad_ubigeo edge cases"
    - path: "tests/unit/test_enaho_loader.py"
      provides: "Unit tests for delimiter sniffing, module loading, dropout construction"
  key_links:
    - from: "src/data/enaho.py"
      to: "src/utils.py"
      via: "imports find_project_root, pad_ubigeo, sniff_delimiter"
      pattern: "from.*utils.*import"
    - from: "src/data/enaho.py"
      to: "data/raw/enaho/2023/"
      via: "file discovery using find_project_root() / data / raw / enaho / {year}"
      pattern: "data.*raw.*enaho"
    - from: "tests/gates/test_gate_1_1.py"
      to: "src/data/enaho.py"
      via: "imports load_enaho_year, calls it with year=2023"
      pattern: "load_enaho_year.*2023"
---

<objective>
Build the ENAHO single-year loader that reads 2023 ENAHO Module 200 (demographics) and Module 300 (education) CSVs, joins them on household/person composite keys, filters to school-age children (6-17), constructs the binary dropout target, and returns a clean polars DataFrame with validated UBIGEO codes and zero nulls on critical columns.

Purpose: This is the foundational data ingestion layer. Every subsequent phase (multi-year, spatial merges, feature engineering, modeling, fairness analysis) depends on this loader producing correct, clean data. Getting dropout target construction and UBIGEO handling right here prevents cascading errors downstream.

Output: `src/utils.py`, `src/data/enaho.py`, unit tests for both, and gate test 1.1 that validates the full pipeline. Human reviews 10 random dropout rows.
</objective>

<execution_context>
@/home/hybridz/.claude/get-shit-done/workflows/execute-plan.md
@/home/hybridz/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-enaho-single-year-loader/01-CONTEXT.md
@.planning/phases/01-enaho-single-year-loader/01-RESEARCH.md
@src/data/download.py
@src/alerta_escuela_audit/__init__.py
@pyproject.toml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create utility functions (find_project_root, pad_ubigeo, sniff_delimiter) with unit tests</name>
  <files>
    src/utils.py
    tests/__init__.py
    tests/unit/__init__.py
    tests/unit/test_ubigeo.py
  </files>
  <action>
    Create `src/utils.py` with three utility functions:

    1. **`find_project_root() -> Path`**: Walk up from caller's file to find directory containing `pyproject.toml`. This is the same pattern used in `src/data/download.py` but extracted as a reusable utility. Raise `RuntimeError` if not found.

    2. **`pad_ubigeo(col: pl.Expr) -> pl.Expr`**: Polars expression that casts to Utf8, strips whitespace, and zero-pads to 6 characters. Use `col.cast(pl.Utf8).str.strip_chars().str.pad_start(6, "0")`. This is a polars expression-level function (returns Expr, not a concrete value).

    3. **`sniff_delimiter(filepath: Path, n_bytes: int = 8192) -> str`**: Read first `n_bytes` of a CSV file using `latin-1` encoding (ENAHO files use latin-1). Use `csv.Sniffer().sniff(sample, delimiters=",|\t;")` to detect delimiter. Fallback: if Sniffer raises `csv.Error`, count delimiter frequencies in the first line and return the most common. Return the detected delimiter character.

    Also refactor `src/data/download.py` to import `find_project_root` from `src/utils.py` instead of defining its own `_find_project_root()`. Remove the local `_find_project_root` function and replace with `from utils import find_project_root` at the top. Keep the `PROJECT_ROOT = find_project_root()` assignment.

    Create `tests/__init__.py` and `tests/unit/__init__.py` as empty files (needed for pytest discovery).

    Create `tests/unit/test_ubigeo.py` with unit tests:
    - `test_pad_ubigeo_short_numeric`: Input "1234" -> "001234"
    - `test_pad_ubigeo_already_six`: Input "010101" -> "010101" (unchanged)
    - `test_pad_ubigeo_with_whitespace`: Input " 1234 " -> "001234" (strips then pads)
    - `test_pad_ubigeo_from_integer`: Input integer 1234 cast to Utf8 -> "001234"
    - `test_pad_ubigeo_preserves_leading_zeros`: Input "010101" as string -> "010101"
    - Each test should create a small polars DataFrame, apply `pad_ubigeo` via `.with_columns()`, and assert the result.

    Create a few tests for `sniff_delimiter` in the same file or `test_enaho_loader.py`:
    - `test_sniff_delimiter_comma`: Write a temp CSV with comma delimiter, verify detection
    - `test_sniff_delimiter_pipe`: Write a temp CSV with pipe delimiter, verify detection

    Run: `uv run pytest tests/unit/test_ubigeo.py -v` to verify all tests pass.
  </action>
  <verify>
    `uv run pytest tests/unit/test_ubigeo.py -v` — all tests pass.
    `uv run python -c "from utils import find_project_root, pad_ubigeo, sniff_delimiter; print('OK')"` — imports work (run from src/ or with PYTHONPATH).
  </verify>
  <done>
    `src/utils.py` exists with 3 exported functions. `tests/unit/test_ubigeo.py` has 7+ passing tests covering pad_ubigeo edge cases and sniff_delimiter detection. `src/data/download.py` imports from utils instead of defining its own root-finder.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create ENAHO module loaders and load_enaho_year() with unit tests</name>
  <files>
    src/data/enaho.py
    tests/unit/test_enaho_loader.py
  </files>
  <action>
    Create `src/data/enaho.py` with the following components:

    **ENAHOResult dataclass:**
    ```python
    from dataclasses import dataclass, field
    import polars as pl

    @dataclass
    class ENAHOResult:
        df: pl.DataFrame
        stats: dict = field(default_factory=dict)
        warnings: list[str] = field(default_factory=list)
    ```

    **`_find_module_file(year_dir: Path, prefix: str, module: str) -> Path`** (private):
    Case-insensitive search for ENAHO module files. Module 200 uses prefix `Enaho01` (no `a`), Module 300 uses prefix `Enaho01a` (with `a`). Search patterns:
    - `{prefix}-{year}-{module}*.csv` (hyphen separator)
    - `{prefix}_{year}_{module}*.csv` (underscore separator)
    - Case variations: as-is, lowercase, uppercase
    If not found, raise `FileNotFoundError` with message: `"Module {module} not found in {year_dir}. Run 'uv run python src/data/download.py' first."`

    **`load_module_200(year: int) -> pl.DataFrame`**:
    1. Resolve data directory: `find_project_root() / "data" / "raw" / "enaho" / str(year)`
    2. Find module file via `_find_module_file(year_dir, "Enaho01", "200")`
    3. Sniff delimiter via `sniff_delimiter(filepath)`
    4. Read CSV with polars: `pl.read_csv(filepath, separator=delimiter, encoding="utf8-lossy", schema_overrides={"UBIGEO": pl.Utf8, "CONGLOME": pl.Utf8, "VIVIENDA": pl.Utf8, "HOGAR": pl.Utf8, "CODPERSO": pl.Utf8})`
    5. Apply `pad_ubigeo` to UBIGEO column
    6. Return DataFrame with at minimum columns: CONGLOME, VIVIENDA, HOGAR, CODPERSO, UBIGEO, P207 (sex), P208A (age)

    **`load_module_300(year: int) -> pl.DataFrame`**:
    Same pattern as 200 but:
    1. Prefix is `"Enaho01a"` (with `a`)
    2. Schema overrides include same join keys as Utf8, plus ensure P303, P306, P307 are read (they may be Int64 or Utf8 depending on year)
    3. Must include columns: CONGLOME, VIVIENDA, HOGAR, CODPERSO, P300A, P303, P306, P307, FACTOR07, P301A

    **`load_enaho_year(year: int) -> ENAHOResult`**:
    1. Call `load_module_200(year)` and `load_module_300(year)`
    2. Join: LEFT join Module 200 onto Module 300 on composite key `["CONGLOME", "VIVIENDA", "HOGAR", "CODPERSO"]`. Use `how="left"` so all people from Module 200 are preserved. This means education variables (P303, P306, etc.) may be null for people not in Module 300.
    3. Filter to school-age: `P208A >= 6` and `P208A <= 17`
    4. **Null check on P303/P306 after join + filter:**
       - Count nulls in P303 and P306 among school-age rows
       - If null fraction < 0.005 (0.5%): fill P303/P306 nulls with conservative value (P303=2 means "was not enrolled" -> dropout=False, which is conservative/safe), add warning
       - If null fraction >= 0.005: raise `ValueError` with diagnostic info (count, fraction, sample rows)
    5. Cast P303 and P306 to Int64 (they may arrive as Utf8 from some years)
    6. Construct dropout target: `dropout = (P303 == 1) & (P306 == 2)` — was enrolled last year AND not enrolled this year. Result is boolean column named `dropout`.
    7. **Strict null validation on critical columns:** UBIGEO, P208A, P303, P306, FACTOR07 must have zero nulls. If any have nulls, raise `ValueError` listing which columns and null counts.
    8. **UBIGEO length validation:** Assert all UBIGEO values have length 6. If any don't, raise `ValueError` with examples.
    9. Compute stats:
       - `total_rows`: number of school-age rows
       - `dropout_count`: unweighted sum of dropout==True
       - `weighted_dropout_rate`: sum(FACTOR07 where dropout) / sum(FACTOR07)
       - `year`: the year
    10. Collect warnings (e.g., null fills, column type coercions)
    11. Return `ENAHOResult(df=df, stats=stats, warnings=warnings)`

    **Column schema validation:** After constructing the final DataFrame, validate that these columns exist with expected types:
    - UBIGEO: Utf8
    - P208A: numeric (Int64 or Float64)
    - P207: numeric
    - P303: Int64
    - P306: Int64
    - P307: numeric or null (nullable)
    - P300A: numeric or Utf8
    - FACTOR07: Float64
    - dropout: Boolean
    Log warnings for unexpected types but don't fail (coerce if possible).

    Create `tests/unit/test_enaho_loader.py` with unit tests using **synthetic data** (no real ENAHO files needed):
    - `test_enahoresult_dataclass`: Verify ENAHOResult fields
    - `test_dropout_construction`: Create tiny DataFrame with known P303/P306 values, verify dropout column is correct
    - `test_school_age_filter`: Verify ages outside 6-17 are excluded
    - `test_ubigeo_validation`: Verify that bad UBIGEO lengths raise or are caught
    - `test_null_critical_columns_detected`: Verify that nulls in FACTOR07 raise ValueError

    Run: `uv run pytest tests/unit/ -v` to verify all tests pass.
  </action>
  <verify>
    `uv run pytest tests/unit/ -v` — all unit tests pass (both test_ubigeo.py and test_enaho_loader.py).
    `uv run python -c "from data.enaho import ENAHOResult, load_enaho_year; print('imports OK')"` — imports work.
  </verify>
  <done>
    `src/data/enaho.py` exists with ENAHOResult dataclass, load_module_200(), load_module_300(), and load_enaho_year(). Unit tests verify dropout construction, age filtering, null validation, and UBIGEO checks using synthetic data. All unit tests pass.
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <name>Task 3: Run gate test 1.1 on real 2023 ENAHO data and review 10 dropout rows</name>
  <what-built>
    Before this checkpoint, the executor creates `tests/gates/test_gate_1_1.py` and `tests/gates/__init__.py`, then runs the gate test against real 2023 ENAHO data.

    **Create `tests/gates/__init__.py`** as empty file.

    **Create `tests/gates/test_gate_1_1.py`** with the following gate test structure:

    ```python
    """Gate Test 1.1: ENAHO Single-Year Loader Validation

    Validates that load_enaho_year(2023) produces correct output:
    - Row count in expected range
    - Dropout count in expected range
    - Weighted dropout rate in expected range
    - UBIGEO integrity (all 6 chars)
    - Zero nulls on critical columns
    - Column schema validation
    - Prints 10 random dropout rows for human inspection
    """
    import sys
    sys.path.insert(0, "src")

    import polars as pl
    from data.enaho import load_enaho_year

    def test_gate_1_1():
        result = load_enaho_year(2023)
        df = result.df
        stats = result.stats

        # Print warnings if any
        if result.warnings:
            print("\n--- WARNINGS ---")
            for w in result.warnings:
                print(f"  WARN: {w}")

        # --- Row count ---
        total = stats["total_rows"]
        assert 18_000 < total < 35_000, f"FAIL: row count {total} outside [18K, 35K]"
        if 20_000 <= total <= 30_000:
            print(f"  PASS: row count = {total}")
        else:
            print(f"  WARN: row count = {total} (outside ideal 20K-30K but within tolerance)")

        # --- Dropout count ---
        dropouts = stats["dropout_count"]
        assert 2_000 < dropouts < 6_000, f"FAIL: dropout count {dropouts} outside [2K, 6K]"
        if 2_500 <= dropouts <= 5_000:
            print(f"  PASS: dropout count = {dropouts}")
        else:
            print(f"  WARN: dropout count = {dropouts} (outside ideal 2.5K-5K but within tolerance)")

        # --- Weighted dropout rate ---
        rate = stats["weighted_dropout_rate"]
        assert 0.08 < rate < 0.22, f"FAIL: weighted rate {rate:.4f} outside [0.08, 0.22]"
        if 0.10 <= rate <= 0.18:
            print(f"  PASS: weighted dropout rate = {rate:.4f}")
        else:
            print(f"  WARN: weighted dropout rate = {rate:.4f} (outside ideal 0.10-0.18 but within tolerance)")

        # --- UBIGEO integrity ---
        ubigeo_lengths = df.select(pl.col("UBIGEO").str.len_chars()).to_series()
        assert (ubigeo_lengths == 6).all(), f"FAIL: not all UBIGEO values are 6 chars"
        print(f"  PASS: all UBIGEO values are 6 characters")

        # --- Null checks on critical columns ---
        critical_cols = ["UBIGEO", "P208A", "P303", "P306", "FACTOR07"]
        for col in critical_cols:
            null_count = df.select(pl.col(col).is_null().sum()).item()
            assert null_count == 0, f"FAIL: {col} has {null_count} nulls"
        print(f"  PASS: zero nulls on critical columns {critical_cols}")

        # --- Column schema validation ---
        expected_cols = ["UBIGEO", "P208A", "P207", "P303", "P306", "FACTOR07", "dropout"]
        for col in expected_cols:
            assert col in df.columns, f"FAIL: missing column {col}"
        print(f"  PASS: all expected columns present")

        # --- Print 10 random dropout rows for human inspection ---
        inspection_cols = ["UBIGEO", "P208A", "P207", "P300A", "P303", "P306", "P307", "P301A", "FACTOR07", "dropout"]
        available_cols = [c for c in inspection_cols if c in df.columns]
        dropout_rows = df.filter(pl.col("dropout") == True)
        sample = dropout_rows.select(available_cols).sample(n=min(10, len(dropout_rows)), seed=42)

        print("\n" + "=" * 80)
        print("HUMAN INSPECTION: 10 Random Dropout Rows")
        print("=" * 80)
        print(f"  Columns: {available_cols}")
        print(sample)
        print("=" * 80)

        # --- Summary ---
        print(f"\n--- GATE TEST 1.1 SUMMARY ---")
        print(f"  Total school-age rows: {total}")
        print(f"  Unweighted dropout count: {dropouts}")
        print(f"  Weighted dropout rate: {rate:.4f}")
        print(f"  Year: {stats['year']}")
        print(f"  Warnings: {len(result.warnings)}")
    ```

    Run: `uv run pytest tests/gates/test_gate_1_1.py -v -s` (with `-s` to show print output).
  </what-built>
  <how-to-verify>
    Review the gate test output:

    1. **Row count**: Should be ~25,000 school-age rows (ages 6-17). If outside 20K-30K, investigate.
    2. **Dropout count**: Should be ~3,500 unweighted dropouts. If outside 2.5K-5K, investigate.
    3. **Weighted dropout rate**: Should be ~14% (0.14). If outside 0.10-0.18, investigate.
    4. **UBIGEO**: All 6 characters, no truncation.
    5. **10 dropout rows**: Verify they look like real student records:
       - UBIGEO looks like a 6-digit Peruvian district code
       - P208A (age) is between 6-17
       - P303=1 (was enrolled last year) and P306=2 (not enrolled this year) — this IS the dropout definition
       - FACTOR07 is a positive survey weight (typically 50-2000)
       - P300A is a mother tongue code (1=Castellano, 2=Quechua, etc.)
       - P207 is sex (1=Male, 2=Female)
    6. **No warnings about excessive nulls or data issues**
  </how-to-verify>
  <resume-signal>Type "approved" if the 10 rows look like real student dropout records, or describe any issues.</resume-signal>
</task>

</tasks>

<verification>
After all tasks complete:
1. `uv run pytest tests/ -v` — ALL tests pass (unit + gate)
2. `load_enaho_year(2023)` returns ENAHOResult with valid DataFrame
3. No nulls on critical columns
4. All UBIGEO values are 6 characters
5. Weighted dropout rate is ~14%
6. Human has reviewed and approved 10 dropout rows
</verification>

<success_criteria>
- `src/utils.py` provides reusable find_project_root, pad_ubigeo, sniff_delimiter
- `src/data/enaho.py` provides ENAHOResult, load_module_200, load_module_300, load_enaho_year
- `tests/unit/test_ubigeo.py` and `tests/unit/test_enaho_loader.py` pass with synthetic data
- `tests/gates/test_gate_1_1.py` passes on real 2023 ENAHO data
- Human approves 10 random dropout rows as realistic student records
</success_criteria>

<output>
After completion, create `.planning/phases/01-enaho-single-year-loader/01-01-SUMMARY.md`
</output>
