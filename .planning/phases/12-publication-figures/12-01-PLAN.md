# Plan 12-01: Publication Figures

## Goal
Create `scripts/publication_figures.py` that generates all publication-quality figures from existing v1.0 exports, plus gate tests to verify figure correctness.

## Pre-conditions
- All v1.0 exports exist in `data/exports/` (JSON + existing PNGs)
- All prediction parquets exist in `data/processed/`
- matplotlib, numpy, polars available in environment

---

## Tasks

### Task 1: Create publication style module
**File:** `src/plotting.py` (new)
**What:** Shared publication styling constants and helpers.
**Details:**
- Define `PUB_STYLE` dict: font sizes (title=14, axis=12, tick=11, legend=10), font family ("serif" for publication)
- Import existing `PALETTE` from `src/data/descriptive.py` and re-export
- Import `FEATURE_LABELS_ES` from `src/fairness/shap_analysis.py` and re-export
- Helper `setup_pub_style()` that calls `plt.rcParams.update()` with publication defaults (serif font, tick direction inward, no top/right spines)
- Helper `save_dual_format(fig, path_stem)` that saves both `{path_stem}.png` (dpi=300, bbox_inches='tight') and `{path_stem}.pdf` (bbox_inches='tight')
- Helper `small_sample_annotation(n, threshold=50)` → returns "*" if n < threshold, "" otherwise
- Keep it minimal — just constants and 2-3 helpers

### Task 2: FIG-01 — Combined PR Curves Panel
**File:** `scripts/publication_figures.py` (new, will grow with each task)
**What:** Single-panel PR curves for LR, LightGBM, XGBoost on test_2023.
**Details:**
- Load `predictions_lr.parquet`, `predictions_lgbm.parquet`, `predictions_xgb.parquet`
- Filter to `split == "test_2023"`
- For each model, compute `precision_recall_curve(y_true, y_prob, sample_weight=FACTOR07)`
- Plot 3 curves on same axes with colors: LR="#1f77b4", LightGBM="#2ca02c", XGBoost="#d62728"
- Legend includes PR-AUC values: e.g., "Logistic Regression (PR-AUC=0.19)"
- Add horizontal baseline line at prevalence rate (weighted dropout rate in test set)
- X-axis: "Recall (Sensitividad)", Y-axis: "Precision (Precisión)"
- Title: "Curvas Precision-Recall — Test 2023"
- Save to `paper/figures/fig01_pr_curves`

### Task 3: FIG-02 — Calibration Curve (polish)
**What:** Regenerate calibration curve at publication quality.
**Details:**
- Load `predictions_lgbm_calibrated.parquet`, filter to `split == "test_2023"`
- Use `CalibrationDisplay.from_predictions()` for uncalibrated (`prob_dropout_uncalibrated`) and calibrated (`prob_dropout`)
- n_bins=10, strategy="uniform"
- Add Brier score in legend: "Calibrado (Brier=0.1156)" etc.
- Title: "Curva de Calibración — LightGBM"
- Save to `paper/figures/fig02_calibration`

### Task 4: FIG-03 — FNR/FPR Grouped Bar by Language (NEW — money figure)
**What:** The headline figure showing surveillance bias vs invisibility bias paradox.
**Details:**
- Load `fairness_metrics.json` → `language.groups`
- Order groups: castellano, quechua, aimara, other_indigenous, foreign (drop "unknown" — flagged as unreliable)
- Plot grouped bar: FNR bars (red "#d62728") and FPR bars (blue "#1f77b4")
- X-axis: language group names (Spanish: "Castellano", "Quechua", "Aimara", "Otros indígenas", "Extranjero")
- Y-axis: "Tasa (0–1)"
- Annotate small samples (n<100) with asterisk on x-tick label
- Add horizontal reference lines at overall FNR and FPR (dashed gray)
- Title: "Tasa de Falsos Negativos y Falsos Positivos por Grupo Lingüístico"
- Add text box explaining: "FNR alto = el modelo no detecta deserción" / "FPR alto = falsas alarmas excesivas"
- Save to `paper/figures/fig03_fnr_fpr_language`

### Task 5: FIG-04 — Dropout Rate Heatmap (polish)
**What:** Regenerate language × rurality dropout rate heatmap at publication quality.
**Details:**
- Load `descriptive_tables.json` → `heatmap_language_x_rural`
- Use existing heatmap pattern from `src/data/descriptive.py` but with pub style
- Colormap: "YlOrRd"
- Cell annotations: rate as percentage + asterisk for n<50
- Title: "Tasa de Deserción: Grupo Lingüístico × Ruralidad"
- Save to `paper/figures/fig04_dropout_heatmap`

### Task 6: FIG-05 — FNR Heatmap Language × Rurality (NEW)
**What:** Shows the urban indigenous blind spot — model's FNR by language and rurality.
**Details:**
- Load `fairness_metrics.json` → `intersections.language_x_rural.groups`
- Parse group names (e.g., "other_indigenous_urban" → row="Otros indígenas", col="Urbano")
- Build matrix: rows=language groups, cols=[Urbano, Rural]
- Fill with FNR values; NaN for missing/flagged groups
- Colormap: "YlOrRd" (higher FNR = redder = worse)
- Cell annotations: FNR as percentage + asterisk for n<50
- Highlight cell other_indigenous_urban (FNR=75.3%) with bold border
- Title: "Tasa de Falsos Negativos: Grupo Lingüístico × Ruralidad"
- Subtitle: "FNR alto = el modelo falla en detectar deserción"
- Save to `paper/figures/fig05_fnr_heatmap`

### Task 7: SHAP figures (polish + re-export)
**What:** Regenerate SHAP bar and beeswarm at publication quality.
**Details:**
- Load `shap_values.json` for feature importance rankings
- Regenerate shap_bar_top10 with Spanish labels, pub style, 300 DPI + PDF
- Regenerate shap_beeswarm with Spanish labels, pub style, 300 DPI + PDF
- Save to `paper/figures/fig06_shap_bar` and `paper/figures/fig07_shap_beeswarm`
- Note: SHAP force plots and regional comparison are supplementary — copy existing PNGs to paper/figures/ as-is (they're harder to restyle without full SHAP objects)

### Task 8: Gate test for publication figures
**File:** `tests/test_gate_pub_figures.py` (new)
**What:** Verify all publication figures exist, have correct properties, and data is accurate.
**Tests:**
1. `paper/figures/` directory exists and contains expected files
2. All 7+ figure stems have both `.png` and `.pdf` versions
3. PNG files have dimensions > 0 and reasonable file sizes (> 10KB)
4. PDF files exist and are non-empty
5. FIG-03 spot-check: load fairness_metrics.json, verify castellano FNR > 0.6 and other_indigenous FPR > 0.5 (the paradox values that should be in the figure)
6. FIG-05 spot-check: verify other_indigenous_urban FNR > 0.7 from source data
7. FIG-01 spot-check: verify 3 models' PR-AUC values match model_results.json (within tolerance)
8. All PNGs are at least 300 DPI (check via PIL Image.info or file size heuristic)

---

## Execution Notes

- `mkdir -p paper/figures/` at script start
- Script should be runnable standalone: `uv run python scripts/publication_figures.py`
- All data loaded from existing exports — no model re-training
- Gate tests run with `uv run pytest tests/test_gate_pub_figures.py -v`
- Total: ~8 figures × 2 formats = 16 files in `paper/figures/`

## Commit Plan
Single commit after all figures generated and gate tests pass:
```
feat(12-01): publication-quality figures for paper
```
