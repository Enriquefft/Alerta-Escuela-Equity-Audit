# M4 Plan: Paper + Media

## Status of What Exists

**Data exports (7 JSON + 1 ONNX + 14 figures):** Complete.
**Code:** Private GitHub repo.
**Findings:** 8 bilingual findings synthesized in `findings.json`.

---

## Deliverable 1: Academic Paper

### Target Venue Options

| Venue | Deadline | Fit | Notes |
|-------|----------|-----|-------|
| **arXiv (cs.CY or cs.LG)** | Anytime | ★★★★★ | Preprint first. Establishes priority. No review delay. |
| **FAccT 2026** | ~Jan 2026 (past) / 2027 TBD | ★★★★★ | Perfect venue — algorithmic fairness in public systems. Check 2027 CFP. |
| **AIES 2026** | TBD (~Mar?) | ★★★★ | AI Ethics and Society. Lighter than FAccT. |
| **LAK (Learning Analytics)** | ~Sep for Mar conf | ★★★★ | Education + ML. Less fairness-focused but strong audience. |
| **JeDI (Journal of Education Data Informatics)** or similar Latin Am. venue | Rolling | ★★★ | Regional impact, Spanish audience |

**Recommendation:** arXiv preprint immediately → submit to FAccT 2027 or AIES 2026. The preprint is the priority — it's citable, establishes date, and supports media pitch.

### Paper Structure (Target: 10–12 pages, ACM format)

```
Title:  "Where You Live, Not Who You Are: An Equity Audit of Peru's
         Alerta Escuela Student Dropout Prediction System"

Abstract (250 words)
  - Peru deploys Alerta Escuela (60 LightGBM models) to predict dropout for
    90,000+ educators. Uses gender, mother tongue, nationality as features.
    Zero published fairness analysis.
  - First independent equity audit using ENAHO 2018–2023 microdata (n=150,112).
  - Key findings: [3 bullets from below]
  - Contributions: methodology for auditing government ML without proprietary data,
    evidence that place-based features outperform identity features, concrete
    fairness-aware alternatives.

1. Introduction (1.5 pages)
   - Alerta Escuela context: national system, 90K+ educators, public money
   - Protected attributes used without fairness analysis
   - Why external audits matter (no SIAGIE access required)
   - Contribution statement

2. Related Work (1 page)
   - Algorithmic fairness in education (Baker & Hawn 2022, etc.)
   - Dropout prediction literature in Latin America
   - External algorithm audits (Buolamwini & Gebru 2018 as methodological precedent)
   - Gap: no fairness audits of education ML in Latin America

3. The Alerta Escuela System (1 page)
   - Architecture: 60 models (12 grades × 5 regions)
   - 31 features from 5 data sources (SIAGIE, ESCALE, NEXUS, ECE, JUNTOS, UE)
   - Protected attributes: ES_MUJER (top 10 for secundaria), LENGUA_MATERNA,
     ES_PERUANO (top predictor for inicial/primaria)
   - Published performance: ROC-AUC 0.84–0.89, FNR 57–64%
   - Zero fairness analysis in methodology document

4. Data & Methods (2 pages)
   4.1 Data
       - ENAHO 2018–2023 microdata (150,112 school-age observations)
       - Dropout definition: P303=1 AND P306=2 (survey-based non-enrollment)
       - Methodological note: ENAHO ~14% vs MINEDU ~2% reflects measurement
         difference, not error. Frame clearly.
       - P300A harmonization (2020 structural break, codes 10–15)
       - Feature proxy mapping: 25 features covering ~60–70% of Alerta Escuela's
         feature space
       - Survey weights (FACTOR07) used throughout
   4.2 Models
       - LightGBM (matching Alerta Escuela), XGBoost, Logistic Regression
       - Temporal split: train 2018–2021, validate 2022, test 2023
       - Platt calibration, threshold optimization (max weighted F1)
   4.3 Fairness Evaluation
       - Metrics: FNR, FPR, TPR, precision, PR-AUC per subgroup
       - Equalized odds gaps, predictive parity
       - 7 dimensions + 3 intersections
       - Fairlearn MetricFrame on calibrated predictions
       - Bootstrap CIs for small-sample groups

5. Results (3 pages) — THE CORE
   5.1 Model Performance
       - Table 1: LR vs LightGBM vs XGBoost (PR-AUC, ROC-AUC, F1, calibration)
       - Algorithm-independence: ratio = 1.0037 → structural, not artifact
       - Figure: PR curves (3 models)
   5.2 Descriptive Disparities
       - Table 2: Dropout rates by language (Castellano 15.3%, Awajún 21.0%,
         other_indigenous 22.2%)
       - Figure: Language × rurality heatmap
   5.3 Fairness Audit — Two-Sided Detection Gap (HEADLINE FINDING)
       - Table 3: FNR/FPR by language group
         - Indigenous: FNR=21.6%, FPR=52.1% (over-flagged, diluting intervention)
         - Castellano: FNR=63.3%, FPR=17.5% (under-detected)
         - Max FNR gap = 0.707 (equalized odds violation)
       - Figure: Grouped bar chart FNR/FPR by language
   5.4 Intersection Analysis
       - Table 4: Language × rurality intersection
         - Urban indigenous: FNR=75.3% (n=89) — worst of both worlds
         - Rural indigenous: FNR=17.1% — model works here
       - Implication: model captures rurality, not linguistic vulnerability
   5.5 What Predicts Dropout? Place, Not Identity
       - Table 5: SHAP top 10 vs LR top 5 (ZERO overlap)
       - SHAP: age, nightlight, is_working, census_indigenous_pct, census_literacy
       - LR: lang_other_indigenous, lang_foreign, lang_quechua, lang_aimara
       - Figure: SHAP bar chart (with proper feature names)
       - Regional SHAP variation (costa vs sierra vs selva)
   5.6 Gender: A Positive Result
       - FNR gap = 3.3% between sexes
       - Shows equity IS achievable in this system

6. Discussion (1.5 pages)
   6.1 The Over-flagging Problem
       - Indigenous students get 3× the false alarm rate of Castellano students
       - Alert fatigue: if 80% of alerts for indigenous students are false,
         teachers stop acting on them
       - Paradox: high TPR for indigenous students sounds good, but at 52% FPR
         the signal is noise
   6.2 The Urban Indigenous Blind Spot
       - Model uses rurality as proxy for vulnerability
       - Indigenous students who migrate to cities lose the rural flag but keep
         the linguistic disadvantage → FNR jumps from 17% to 75%
   6.3 Place-Based vs Identity-Based Features
       - Zero SHAP/LR overlap suggests two different causal stories
       - LR: "who you are" (language, nationality) → identity-based risk
       - SHAP: "where you are" (nightlight, census indicators) → structural risk
       - Policy implication: invest in places, not label people
   6.4 Limitations
       - ENAHO survey vs SIAGIE admin data (different populations, different
         dropout definitions)
       - Missing variables: grades, attendance, prior dropout (individual academic)
       - Small samples for disaggregated indigenous groups
       - Cannot directly evaluate Alerta Escuela (no model access) — this is
         an audit of the APPROACH, not the specific model

7. Recommendations (0.5 pages)
   - Publish fairness analysis alongside model performance
   - Add place-based features (nightlights, census indicators) to Alerta Escuela
   - Report FNR by language group as standard practice
   - Consider threshold calibration per region
   - Address urban indigenous blind spot with targeted indicators

8. Conclusion (0.5 pages)

Appendix
   - Full feature list and proxy mapping (Table A1)
   - P300A harmonization details
   - Threshold sensitivity analysis
   - All disaggregated fairness tables
```

### Figures Needed (Publication Quality)

All figures must use proper feature names, consistent styling, and be print-ready.

| # | Figure | Current Status | Action |
|---|--------|---------------|--------|
| 1 | PR curves (3 models, one panel) | 3 separate files, OK quality | Combine into single panel |
| 2 | Calibration curve | OK quality | Keep, minor label cleanup |
| 3 | FNR/FPR grouped bar by language | Exists in findings but not as standalone | **Create new** — this is the money figure |
| 4 | Language × rurality heatmap (dropout rates) | Exists, OK | Clean up labels |
| 5 | Language × rurality heatmap (FNR) | **Does not exist** | **Create new** — shows urban indigenous gap |
| 6 | SHAP bar chart (top 10) | ✅ Fixed (proper feature names) | Publication polish only |
| 7 | SHAP beeswarm | ✅ Fixed (proper feature names) | Publication polish only |
| 8 | SHAP regional comparison | ✅ Fixed | Publication polish only |
| 9 | SHAP force plots (es_mujer, es_peruano) | ✅ Fixed | Publication polish only |
| 10 | Temporal trends | Exists, OK quality | Keep |

**Estimated remaining figure work: ~2 hours** (FNR grouped bar, FNR×rurality heatmap, PR curve merge, polish).

### Tables Needed

| # | Table | Source |
|---|-------|--------|
| 1 | Model performance comparison (3 models × val/test) | model_results.json |
| 2 | Weighted dropout rates by language group (with CIs) | descriptive_tables.json |
| 3 | Fairness metrics by language group (FNR, FPR, TPR, precision, n) | fairness_metrics.json |
| 4 | Intersection: language × rurality (FNR, n) | fairness_metrics.json intersections |
| 5 | SHAP top 10 vs LR top 5 | shap_values.json |
| A1 | Full feature list with Alerta Escuela proxy mapping | project spec |
| A2 | P300A harmonization table | P300A_coding_consistency doc |

---

## Deliverable 2: Media Strategy

### The Story (One Sentence)

**English:** "Peru's AI system for predicting school dropouts overwhelms indigenous students with false alarms while failing to detect 6 in 10 at-risk Spanish-speaking students — and no one checked for bias."

**Spanish:** "El sistema de IA del Perú para predecir la deserción escolar satura a los estudiantes indígenas con alertas falsas mientras no detecta a 6 de cada 10 estudiantes hispanohablantes en riesgo — y nadie revisó si era justo."

### Why This Story Works for Media

1. **Government AI system** — public money, public accountability
2. **Affects children** — emotional weight
3. **Indigenous communities** — equity angle that resonates globally
4. **Counterintuitive finding** — it's NOT "AI ignores indigenous students." It's "AI over-flags them while missing everyone else." This is more interesting and more nuanced than the expected narrative.
5. **First audit** — novelty, no one else has done this
6. **Concrete numbers** — FNR 63.3%, FPR 52.1%, 500K+ students affected
7. **Constructive framing** — findings.json already frames everything as "opportunities for improvement," not attacks

### Target Media (Ordered by Impact)

**Tier 1 — Peru (primary target, Spanish):**
| Outlet | Why | Contact approach |
|--------|-----|-----------------|
| **El Comercio** (data/tech section) | Largest newspaper, has data journalism team | Email data desk directly |
| **Ojo Público** | Investigative journalism, specializes in data stories + government accountability | Perfect fit — they've done algorithmic accountability before |
| **La República** | Large readership, education coverage | Education desk |
| **COES (Centro de Investigación)** | Academic but media-connected, inequality research | They amplify through their network |
| **RPP Noticias** | Radio + digital, broad reach | Pitch as interview |

**Tier 2 — Latin America (Spanish):**
| Outlet | Why |
|--------|-----|
| **Rest of World** | Covers tech in Global South, English + Spanish reach |
| **MIT Technology Review en Español** | Tech + policy audience |
| **El País (América)** | Broad LATAM readership |

**Tier 3 — International (English):**
| Outlet | Why |
|--------|-----|
| **Algorithm Watch** | Algorithmic accountability — exactly their beat |
| **The Markup** | Data-driven tech accountability journalism |
| **MIT Technology Review** | If LATAM angle is strong enough |

### Media Timeline

**Do NOT pitch before the arXiv preprint is live.** The preprint is your credibility anchor — journalists will link to it. Without it, you're just "some guy with claims."

```
Week 1: Fix figures + write paper
Week 2: Finish paper, submit to arXiv
Week 3: arXiv live → pitch media (Ojo Público first, then El Comercio)
Week 4: Follow up, respond to questions, publish blog post
```

### Media Kit (Prepare Before Pitching)

| Asset | Format | Purpose |
|-------|--------|---------|
| **Press summary (ES)** | 1-page PDF | Attach to pitch emails. Plain language, 5 key numbers, one figure. |
| **Press summary (EN)** | 1-page PDF | For international outlets |
| **Key figures pack** | 3–4 PNGs (high-res) | The money charts journalists can embed |
| **Blog post (ES)** | Web (Medium/personal) | Longer explanation for public, link in pitches |
| **Blog post (EN)** | Web | International version |
| **GitHub repo (public)** | Link | Credibility — "all code is open" |
| **One-liner bio** | Text | "Enrique Flores, CTO de Genera (edtech, 500+ docentes), fundador de 404 Tech Found" |

### Pitch Email Template (Spanish, for Ojo Público)

```
Asunto: Primera auditoría de equidad del sistema de IA Alerta Escuela del MINEDU

Hola [nombre],

Realicé la primera auditoría independiente de equidad del sistema Alerta
Escuela del MINEDU, que usa inteligencia artificial para predecir deserción
escolar y llega a 90,000+ docentes.

Hallazgo principal: el sistema satura a estudiantes indígenas con alertas
falsas (52% de tasa de falsos positivos) mientras no detecta a 6 de cada 10
estudiantes hispanohablantes que abandonan la escuela. Nadie había evaluado
si el sistema es equitativo.

El estudio usa datos públicos de ENAHO (150,000+ observaciones, 2018–2023)
y está disponible como preprint: [link arXiv]

¿Les interesaría cubrir esto? Puedo compartir el resumen ejecutivo y las
visualizaciones.

Enrique Flores
CTO, Genera (AI edtech, 500+ docentes en sector público)
Fundador, 404 Tech Found (primera incubadora deeptech del Perú)
```

---

## M4 Execution Plan

### Week 1: Fix + Write (Days 1–7)

**Days 1–2: New figures + paper setup**
- [ ] Create FNR/FPR grouped bar chart by language (the headline figure for paper + media)
- [ ] Create FNR heatmap for language × rurality intersection (urban indigenous gap)
- [ ] Combine PR curves into single 3-panel figure
- [ ] Polish existing figures for print (font sizes, axis labels, consistent color scheme)
- [ ] Set up LaTeX template (ACM or arXiv-friendly)

**Days 3–5: Write paper**
- [ ] Set up LaTeX template (ACM or arXiv-friendly)
- [ ] Write Sections 1–3 (Introduction, Related Work, System Description)
- [ ] Write Section 4 (Data & Methods) — already mostly documented in project spec
- [ ] Write Section 5 (Results) — pull directly from fairness_metrics.json + findings.json
- [ ] Write Section 6 (Discussion) — the urban indigenous blind spot is the narrative core
- [ ] Write Section 7 (Recommendations) + Conclusion

**Days 6–7: Tables + polish**
- [ ] Generate all tables from JSON exports
- [ ] Write Abstract (last — after results are finalized)
- [ ] Internal review pass: check all numbers match JSON sources
- [ ] Proofread

### Week 2: Submit + Prep Media (Days 8–14)

**Days 8–9: Paper finalization + repo cleanup**
- [ ] Second review pass
- [ ] Ensure reproducibility: clean GitHub repo, verify all scripts run
- [ ] Make repo public (or prepare to make public on arXiv submission day)
- [ ] Submit to arXiv (cs.CY primary, cs.LG secondary)

**Days 10–12: Media kit**
- [ ] Write 1-page press summary (Spanish)
- [ ] Write 1-page press summary (English)
- [ ] Select and export 3–4 key high-res figures for journalists
- [ ] Write blog post (Spanish) — 800–1200 words, accessible language
- [ ] Write blog post (English)

**Days 13–14: Pitch**
- [ ] Wait for arXiv to go live (usually 1–2 business days)
- [ ] Send pitch to Ojo Público
- [ ] Send pitch to El Comercio data desk
- [ ] Post on LinkedIn (Spanish) with key figure
- [ ] Post on Twitter/X with key finding

### Week 3: Follow-up + Expand (Days 15–21)

- [ ] Respond to journalist questions
- [ ] Send to Tier 2 outlets if Tier 1 doesn't bite
- [ ] Send to international outlets (Algorithm Watch, Rest of World)
- [ ] Submit to FAccT 2027 / AIES 2026 if deadline aligns
- [ ] Share with MINEDU (optional — after media, not before. Media creates pressure for response.)

---

## Narrative Decisions

### Framing: Constructive, Not Adversarial

Your findings.json already does this well. The paper should follow the same tone:

- ❌ "Alerta Escuela discriminates against indigenous students"
- ✅ "Alerta Escuela has a two-sided detection gap that could be addressed with place-based features"

Why: (1) You might want to work with MINEDU eventually. (2) Constructive framing gets more media pickup — editors want solutions, not just problems. (3) It's more accurate — the system doesn't "discriminate" in a simple way; the bias pattern is nuanced.

### The Urban Indigenous Finding is Your Narrative Core

The most interesting finding is NOT the overall language gap. It's the intersection: **urban indigenous students have FNR=75.3%** while rural indigenous students have FNR=17.1%.

This tells a clear story: the model uses rurality as a proxy for vulnerability. Indigenous students in rural areas get detected because they're rural. Indigenous students who migrate to cities lose the rural flag but keep the linguistic disadvantage — they fall through both cracks.

**This is the finding that makes journalists call you back.** It's counterintuitive, it's specific, and it points to a clear policy fix (add urban vulnerability indicators for linguistic minorities).

### The SHAP Zero-Overlap Finding is Your Academic Core

For the paper, the strongest methodological contribution is that SHAP and LR identify completely different feature sets (0/5 overlap). This frames the entire discussion about structural vs. identity-based risk and justifies the title: "Where You Live, Not Who You Are."

---

## Risk Assessment

| Risk | Probability | Mitigation |
|------|-------------|------------|
| MINEDU pushback ("your data is different from ours") | High | Preempt in Section 4: "This is an audit of the *approach*, not the specific model. ENAHO measures different phenomenon than SIAGIE." |
| "Your model only gets PR-AUC 0.24 — why should we listen?" | Medium | Frame clearly: "We intentionally replicate Alerta Escuela's approach with public data. The *performance* is secondary; the *fairness gaps* are the contribution." |
| Small sample criticism (n=89 for urban indigenous) | Medium | Report with bootstrap CIs. Acknowledge. Frame as "signal that warrants investigation with SIAGIE data, not definitive proof." |
| No media pickup | Low-Medium | Ojo Público is very likely to cover this. Have blog post as fallback for direct reach. |

---

## What I Can Help Build Right Now

If you want to start executing, the highest-value things I can help with immediately:

1. **LaTeX paper template** with the full structure pre-filled (sections, placeholder figures/tables)
2. **Figure regeneration scripts** — Python code to re-render SHAP plots with real feature names from your JSON exports
3. **Press summary** (1-page PDF, Spanish and English)
4. **Blog post** draft (Spanish)
5. **Pitch emails** for specific journalists

What do you want to start with?
